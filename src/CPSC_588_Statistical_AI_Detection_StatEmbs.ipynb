{"cells":[{"cell_type":"markdown","metadata":{"id":"Du0JyQJvj-2k"},"source":["### Setup: Install and import"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20131,"status":"ok","timestamp":1702885652769,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"InR32FS70N5v","outputId":"7f75c530-d9b4-4b62-dcaf-39be12dd190c"},"outputs":[],"source":["!pip install transformers torch\n","!pip install nltk\n","!pip install tqdm\n","!pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2280,"status":"ok","timestamp":1702885655045,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"7t46zhfzczpR","outputId":"2cb2debc-eb92-4e86-a55e-15d69af59ba9"},"outputs":[],"source":["# In order to make things work on google drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3061,"status":"ok","timestamp":1702885658103,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"Cg1GBJFJEgGf"},"outputs":[],"source":["import random\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, AdamW\n","import nltk\n","\n","from tqdm import tqdm\n","import numpy as np\n","\n","import openai"]},{"cell_type":"markdown","metadata":{"id":"80Icgps6EiDz"},"source":["### Load Pre-trained RoBERTa Model and Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1848,"status":"ok","timestamp":1702885674419,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"-_rU-1hnEl6L","outputId":"24533dfc-b4b3-4568-9125-7cbe49af9a97"},"outputs":[],"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","roberta_base = RobertaModel.from_pretrained('roberta-base')"]},{"cell_type":"markdown","metadata":{"id":"8h2vfTkIPyiM"},"source":["### Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5281,"status":"ok","timestamp":1702885679697,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"NHbKUtamRDnF","outputId":"29b77dc6-dacc-4eef-8915-ba5c496af977"},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2663,"status":"ok","timestamp":1702885682344,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"CTd8SQe7P7wk"},"outputs":[],"source":["# GPT- wiki-intro\n","# https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"aadityaubhat/GPT-wiki-intro\")['train']"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1702885682344,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"lKzG3H3jaTEs"},"outputs":[],"source":["# truncate\n","def truncate(example):\n","    \"\"\"\n","    Truncate 'wiki_intro' and 'generated_intro' to shorter length\n","    \"\"\"\n","    min_length = min(len(example['wiki_intro']), len(example['generated_intro']))\n","    truncated_wiki_intro = example['wiki_intro'][:min_length]\n","    truncated_generated_intro = example['generated_intro'][:min_length]\n","\n","    return {\n","        'wiki_intro': truncated_wiki_intro,\n","        'generated_intro': truncated_generated_intro,\n","        'title_len': example['title_len'],\n","        'wiki_intro_len': example['wiki_intro_len'],\n","        'generated_intro_len': example['generated_intro_len'],\n","        'prompt_tokens': example['prompt_tokens'],\n","        'generated_text_tokens': example['generated_text_tokens']\n","    }\n","\n","\n","# Wiki_train_data = Wiki_train_data.map(truncate)\n","# Wiki_val_data = Wiki_val_data.map(truncate)\n","# Wiki_test_data = Wiki_test_data.map(truncate)\n","Wiki_data = dataset.map(truncate)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":926,"status":"ok","timestamp":1702885683549,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"dp0ylch3b3vY"},"outputs":[],"source":["# Generate labels\n","Wiki_texts = Wiki_data['wiki_intro'] + Wiki_data['generated_intro']\n","\n","# 1 for human generated, 0 for machine generated\n","Wiki_labels = [1] * len(Wiki_data['wiki_intro']) + [0] * len(Wiki_data['generated_intro'])"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702885683550,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"8jnQK78ljdMe"},"outputs":[],"source":["def downsample_data(texts, labels, num_samples=2000):\n","    random.seed(42)\n","    combined_data = list(zip(texts, labels))\n","    sampled_data = random.sample(combined_data, num_samples)\n","    sampled_texts, sampled_labels = zip(*sampled_data)\n","    sampled_indices = [texts.index(text) for text, label in sampled_data]\n","\n","    return list(sampled_texts), list(sampled_labels), sampled_indices"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":11381,"status":"ok","timestamp":1702885694927,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"vogXQSEIgfzb"},"outputs":[],"source":["Wiki_sampled_texts, Wiki_sampled_labels, Wiki_sampled_indices = downsample_data(Wiki_texts, Wiki_labels, 2000)\n","\n","Wiki_train_texts = Wiki_sampled_texts[:1700]\n","Wiki_train_labels = Wiki_sampled_labels[:1700]\n","Wiki_train_indices = Wiki_sampled_indices[:1700]\n","\n","Wiki_val_texts = Wiki_sampled_texts[1700:1850]\n","Wiki_val_labels = Wiki_sampled_labels[1700:1850]\n","Wiki_val_indices = Wiki_sampled_indices[1700:1850]\n","\n","Wiki_test_texts = Wiki_sampled_texts[1850:]\n","Wiki_test_labels = Wiki_sampled_labels[1850:]\n","Wiki_test_indices = Wiki_sampled_indices[1850:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1702885694928,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"cy5EPcMRragj","outputId":"5a67d84c-7326-4932-be43-e6a9de9878c6"},"outputs":[],"source":["print(f\"Training Data Size: {len(Wiki_train_texts)}\")\n","print(f\"Validation Data Size: {len(Wiki_val_texts)}\")\n","print(f\"Testing Data Size: {len(Wiki_test_texts)}\")\n","\n","print(Wiki_train_indices)\n","print(Wiki_val_indices)\n","print(Wiki_test_indices)\n","\n","print(\"first string in Wiki_train_texts:\", Wiki_train_texts[0])\n","print(\"first label in Wiki_train_texts:\", Wiki_train_labels[0])\n","print(\"first index in Wiki_train_texts:\", Wiki_train_indices[0])\n","print(\"this index in texts:\", Wiki_texts[Wiki_train_indices[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5331,"status":"ok","timestamp":1702885700249,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"Cc5SWSjwZZ0e","outputId":"f145ee0b-19c0-49b5-d27e-ffd99468e80e"},"outputs":[],"source":["# PubMedQA\n","# https://pubmedqa.github.io/\n","\n","# a directory structure in Files:\n","# data/ori_pqaa.json      - 2.6 MB Downloaded from https://drive.google.com/file/d/15v1x6aQDlZymaHGP7cZJZZYFfeJt2NdS/view\n","# data/ori_pqal.json      - 533.4 MB Downloaded from https://github.com/pubmedqa/pubmedqa/blob/master/data/ori_pqal.json\n","import json\n","import random\n","\n","ori_pqal_path = './gdrive/MyDrive/CPSC_588_dataset/ori_pqal.json'\n","with open(ori_pqal_path, 'r') as file:\n","    ori_pqal = json.load(file)\n","machine_generated_dataset = [{\"text\": item[\"LONG_ANSWER\"], \"label\": \"0\"} for item in ori_pqal.values()]\n","\n","ori_pqaa_path = './gdrive/MyDrive/CPSC_588_dataset/ori_pqaa.json'\n","with open(ori_pqaa_path, 'r') as file:\n","    ori_pqaa = json.load(file)\n","human_generated_dataset = [{\"text\": item[\"LONG_ANSWER\"], \"label\": \"1\"} for item in ori_pqaa.values()]\n","\n","random.seed(0)\n","human_generated_dataset = random.sample(human_generated_dataset, 1000)\n","\n","print(machine_generated_dataset[0]) # {'text': '...', 'label': 'machine_generated'}\n","print(human_generated_dataset[0]) # {'text': '...', 'label': 'human_generated'}"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1702885700249,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"dCa7GbfT-_wg"},"outputs":[],"source":["combined_dataset = machine_generated_dataset + human_generated_dataset\n","\n","texts = [item['text'] for item in combined_dataset]\n","labels = [int(item['label']) for item in combined_dataset]\n","\n","PMQA_train_texts, temp_texts, PMQA_train_labels, temp_labels = train_test_split(\n","    texts, labels, test_size=0.2, random_state=42)\n","\n","PMQA_val_texts, PMQA_test_texts, PMQA_val_labels, PMQA_test_labels = train_test_split(\n","    temp_texts, temp_labels, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702885700249,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"S4L6KNrT_Ayy"},"outputs":[],"source":["PMQA_sampled_texts, PMQA_sampled_labels, PMQA_sampled_indices = downsample_data(texts, labels, 2000)\n","\n","PMQA_train_texts = PMQA_sampled_texts[:1700]\n","PMQA_train_labels = PMQA_sampled_labels[:1700]\n","PMQA_train_indices = PMQA_sampled_indices[:1700]\n","\n","PMQA_val_texts = PMQA_sampled_texts[1700:1850]\n","PMQA_val_labels = PMQA_sampled_labels[1700:1850]\n","PMQA_val_indices = PMQA_sampled_indices[1700:1850]\n","\n","PMQA_test_texts = PMQA_sampled_texts[1850:]\n","PMQA_test_labels = PMQA_sampled_labels[1850:]\n","PMQA_test_indices = PMQA_sampled_indices[1850:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702885700249,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"XdPADCgP_CC8","outputId":"ac081003-e701-4784-d41f-729c33c07d72"},"outputs":[],"source":["print(f\"Training Data Size: {len(PMQA_train_texts)}\")\n","print(f\"Validation Data Size: {len(PMQA_val_texts)}\")\n","print(f\"Testing Data Size: {len(PMQA_test_texts)}\")\n","\n","print(\"first string in PMQA_train_texts:\", PMQA_train_texts[0])\n","print(\"first label in PMQA_train_texts:\", PMQA_train_labels[0])\n","print(\"first index in PMQA_train_texts:\", PMQA_train_indices[0])\n","print(\"this index in texts:\", texts[PMQA_train_indices[0]])"]},{"cell_type":"markdown","metadata":{"id":"TFtHvthyE34H"},"source":["### Data Preparation"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702885700250,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"PH19Mj7IM4hW"},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=512):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","          text,\n","          add_special_tokens=True,\n","          max_length=self.max_len,\n","          return_token_type_ids=False,\n","          padding='max_length',\n","          return_attention_mask=True,\n","          return_tensors='pt',\n","          truncation=True\n","        )\n","\n","        return {\n","          'text': text,\n","          'input_ids': encoding['input_ids'].flatten(),\n","          'attention_mask': encoding['attention_mask'].flatten(),\n","          'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","Wiki_train_dataset = TextDataset(Wiki_train_texts, Wiki_train_labels, tokenizer)\n","Wiki_val_dataset = TextDataset(Wiki_train_texts, Wiki_train_labels, tokenizer)\n","Wiki_test_dataset = TextDataset(Wiki_train_texts, Wiki_train_labels, tokenizer)\n","\n","Wiki_train_loader = DataLoader(Wiki_train_dataset, batch_size=16, shuffle=True)\n","Wiki_val_loader = DataLoader(Wiki_val_dataset, batch_size=16, shuffle=True)\n","Wiki_test_loader = DataLoader(Wiki_test_dataset, batch_size=16, shuffle=True)\n","\n","PMQA_train_dataset = TextDataset(PMQA_train_texts, PMQA_train_labels, tokenizer)\n","PMQA_val_dataset = TextDataset(PMQA_val_texts, PMQA_val_labels, tokenizer)\n","PMQA_test_dataset = TextDataset(PMQA_test_texts, PMQA_test_labels, tokenizer)\n","\n","PMQA_train_loader = DataLoader(PMQA_train_dataset, batch_size=16, shuffle=True)\n","PMQA_val_loader = DataLoader(PMQA_val_dataset, batch_size=16, shuffle=False)\n","PMQA_test_loader = DataLoader(PMQA_test_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"SPf-nItAMxG6"},"source":["### Create a Custom Classifier"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702885700250,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"h2yuRC4hE0Yb"},"outputs":[],"source":["class BaselineRobertaClassifier(nn.Module):\n","    def __init__(self, roberta_base):\n","        super(BaselineRobertaClassifier, self).__init__()\n","        self.roberta = roberta_base\n","        self.classifier = nn.Linear(roberta_base.config.hidden_size, 2)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.roberta(input_ids, attention_mask)\n","        pooled_output = outputs[1]\n","        logits = self.classifier(pooled_output)\n","        return logits\n","\n","class RobertaClassifier(nn.Module):\n","    def __init__(self, roberta_base, stat_emb_dim, fusion_type='early'):\n","        super(RobertaClassifier, self).__init__()\n","        self.fusion_type = fusion_type\n","        self.roberta = roberta_base\n","\n","        # Non-linear transformation for statistical embeddings\n","        self.stat_emb_transform = nn.Linear(stat_emb_dim, stat_emb_dim)\n","        self.activation = nn.ReLU()\n","\n","        if fusion_type == 'early':\n","            self.classifier = nn.Linear(roberta_base.config.hidden_size + stat_emb_dim, 2)\n","        else:  # late fusion\n","            self.classifier = nn.Linear(roberta_base.config.hidden_size, 2)\n","            self.stat_emb_classifier = nn.Linear(stat_emb_dim, 2)\n","\n","            # Conditional layer\n","            self.conditional_weights = nn.Linear(stat_emb_dim, roberta_base.config.hidden_size)\n","\n","    def forward(self, input_ids, attention_mask, statistical_features):\n","        outputs = self.roberta(input_ids, attention_mask)\n","        pooled_output = outputs[1]\n","\n","        # Apply non-linear transformation to statistical features\n","        transformed_stat_features = self.activation(self.stat_emb_transform(statistical_features))\n","\n","        if self.fusion_type == 'early':\n","            combined_output = torch.cat((pooled_output, transformed_stat_features), dim=1)\n","            return self.classifier(combined_output)\n","        else:  # late fusion\n","            # Apply conditional layer\n","            conditional_weights = torch.sigmoid(self.conditional_weights(transformed_stat_features))\n","            conditioned_roberta_output = pooled_output * conditional_weights\n","\n","            logits_from_roberta = self.classifier(conditioned_roberta_output)\n","            logits_from_stat_emb = self.stat_emb_classifier(transformed_stat_features)\n","            combined_logits = logits_from_roberta + logits_from_stat_emb\n","            return combined_logits"]},{"cell_type":"markdown","metadata":{"id":"07FwZCgfuXZL"},"source":["### Calculate the statistical features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1702885700539,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"7cM5PoOOytjv","outputId":"52dc4322-fed8-4e9e-a48b-840a68244363"},"outputs":[],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.help.upenn_tagset()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702885700540,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"2hpq_0402Xim","outputId":"6c5526a4-1794-4ace-a8ce-f0125fbe3bac"},"outputs":[],"source":["from nltk.data import load\n","upenn_tagset_info = load('help/tagsets/upenn_tagset.pickle')\n","upenn_tagset = list(upenn_tagset_info.keys())\n","#print(upenn_tagset)\n","#print(len(upenn_tagset))\n","for index, tag in enumerate(upenn_tagset):\n","    print(f\"index:{index} , tag:{tag}\")\n","upenn_tagset_meaningful = upenn_tagset[0:3] + upenn_tagset[4:9] + upenn_tagset[10:14] + upenn_tagset[15:19] + upenn_tagset[25:]\n","#print(upenn_tagset_meaningful)\n","#print(len(upenn_tagset_meaningful))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702885700540,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"B1uFkVYxArfN"},"outputs":[],"source":["import json\n","import pandas as pd"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702885700540,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"-zst-5gnywe_"},"outputs":[],"source":["def calculate_tag_dist(text: str):\n","    text = nltk.tokenize.word_tokenize(text)\n","    tagged_text = nltk.pos_tag(text)\n","    tag_fd = nltk.FreqDist(tag for (word, tag) in tagged_text)\n","    tag_count = [tag_fd.get(tag, 0) for tag in upenn_tagset_meaningful]\n","    count_sum = sum(tag_count)\n","    tag_dist = [count / count_sum for count in tag_count]\n","    # tag_dist = [tag_fd.freq(tag) for tag in tag_fd]\n","    # print(dict(tag_fd))\n","    # print(\"length\", len(tag_dist))\n","    # print(tag_dist)\n","    return tag_dist\n","\n","def calculate_statistical_features_pos(input_text):\n","    # Implement the logic to calculate statistical features\n","    # This function should return a tensor of shape [batch_size, stat_emb_dim]\n","    # pos tag distribution\n","    pos_tag_dists = [calculate_tag_dist(text) for text in input_text]\n","    return torch.tensor(pos_tag_dists)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4933,"status":"ok","timestamp":1702885705470,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"KTh9LCpQdmVs","outputId":"12304b17-bff2-4ec9-afd2-561220d65cca"},"outputs":[],"source":["!pip install py-readability-metrics"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702885705470,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"z72uCTAXdny4"},"outputs":[],"source":["from readability import Readability"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702885705470,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"21mJeUpSdrIT"},"outputs":[],"source":["def calculate_readability_metrics(text):\n","    metrics = []\n","    r = Readability(text)\n","    metrics.append(r.flesch_kincaid().score)\n","    metrics.append(r.flesch().score)\n","    metrics.append(r.gunning_fog().score)\n","    metrics.append(r.coleman_liau().score)\n","    metrics.append(r.dale_chall().score)\n","    metrics.append(r.ari().score)\n","    metrics.append(r.linsear_write().score)\n","    # metrics.append(r.smog().score)\n","    metrics.append(r.spache().score)\n","    return metrics\n","\n","def calculate_statistical_features_readability(input_text):\n","    # Implement the logic to calculate statistical features\n","    # This function should return a tensor of shape [batch_size, stat_emb_dim]\n","    # readability measure\n","    readability_metrics = []\n","    for text in input_text:\n","        appended = False\n","        text_pad = text\n","        for i in range(100):\n","            try:\n","                readability_metrics.append(calculate_readability_metrics(text_pad))\n","                appended = True\n","            except:\n","                text_pad += text\n","                continue\n","            break\n","        if i == 99:\n","            if not appended:\n","                readability_metrics.append(([0] * 8))\n","    return torch.tensor(readability_metrics)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702885705470,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"MsCoEPFKhXnn"},"outputs":[],"source":["def calculate_statistical_features(input_text):\n","    pos_embs = calculate_statistical_features_pos(input_text)\n","    read_embs = calculate_statistical_features_readability(input_text)\n","    return torch.cat((pos_embs, read_embs), dim=1)"]},{"cell_type":"markdown","metadata":{"id":"cAswQlD1M3Gv"},"source":["### Model Training"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702885705470,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"sYhc6dQU2Lvq"},"outputs":[],"source":["def train_epoch_baseline(model, data_loader, loss_fn, optimizer, device, n_examples):\n","    model.train()\n","    losses = []\n","    correct_predictions = 0\n","\n","    for d in tqdm(data_loader, total=len(data_loader), desc=\"Training\"):\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        labels = d[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(outputs, dim=1)\n","        loss = loss_fn(outputs, labels)\n","\n","        correct_predictions += torch.sum(preds == labels)\n","        losses.append(loss.item())\n","\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    return correct_predictions.double() / n_examples, np.mean(losses)\n","\n","def train_epoch_stat_only(model, data_loader, loss_fn, optimizer, device, n_examples, calculate_stat_features):\n","    model.train()\n","    losses = []\n","    correct_predictions = 0\n","\n","    for d in tqdm(data_loader, total=len(data_loader), desc=\"Training\"):\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        labels = d[\"labels\"].to(device)\n","        texts = d[\"text\"]\n","        stat_features = calculate_stat_features(texts).to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n","        _, preds = torch.max(outputs, dim=1)\n","        loss = loss_fn(outputs, labels)\n","\n","        correct_predictions += torch.sum(preds == labels)\n","        losses.append(loss.item())\n","\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    return correct_predictions.double() / n_examples, np.mean(losses)\n","\n","def validate_epoch(model, data_loader, loss_fn, device, n_examples, calculate_stat_features):\n","    model.eval()\n","    losses = []\n","    correct_predictions = 0\n","\n","    with torch.no_grad():\n","        for d in data_loader:\n","            input_ids = d[\"input_ids\"].to(device)\n","            attention_mask = d[\"attention_mask\"].to(device)\n","            labels = d[\"labels\"].to(device)\n","            texts = d[\"text\"]\n","            stat_features = calculate_stat_features(texts).to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n","            _, preds = torch.max(outputs, dim=1)\n","            loss = loss_fn(outputs, labels)\n","\n","            correct_predictions += torch.sum(preds == labels)\n","            losses.append(loss.item())\n","\n","    return correct_predictions.double() / n_examples, np.mean(losses)\n","\n","def eval_model(model, data_loader, loss_fn, device, n_examples, calculate_stat_features):\n","    model = model.eval()\n","    losses = []\n","    correct_predictions = 0\n","\n","    with torch.no_grad():\n","        for d in tqdm(data_loader, total=len(data_loader), desc=\"Testing\"):\n","            input_ids = d[\"input_ids\"].to(device)\n","            attention_mask = d[\"attention_mask\"].to(device)\n","            labels = d[\"labels\"].to(device)\n","            stat_features = calculate_stat_features(d[\"text\"]).to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n","            _, preds = torch.max(outputs, dim=1)\n","            loss = loss_fn(outputs, labels)\n","\n","            correct_predictions += torch.sum(preds == labels)\n","            losses.append(loss.item())\n","\n","    return correct_predictions.double() / n_examples, np.mean(losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476525,"status":"ok","timestamp":1702904542562,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"9_kHHHeI9FaP","outputId":"34d4ff2d-48a7-45ad-be75-f48c94cbdd85"},"outputs":[],"source":["# Initialize model\n","dataset = \"Wiki\"\n","# dataset = \"PMQA\"\n","\n","num_epochs = 5\n","stat_emb_dim = 8\n","fusion_type = \"late\"\n","\n","model = RobertaClassifier(roberta_base, stat_emb_dim, fusion_type)\n","stat_fn = calculate_statistical_features_readability\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    print('-' * 10)\n","\n","    train_acc, train_loss = train_epoch_stat_only(\n","        model,\n","        Wiki_train_loader if dataset == \"Wiki\" else PMQA_train_loader,\n","        loss_fn,\n","        optimizer,\n","        device,\n","        len(Wiki_train_dataset) if dataset == \"Wiki\" else len(PMQA_train_dataset),\n","        stat_fn\n","    )\n","    print(f'Train loss {train_loss}, accuracy {train_acc}')\n","\n","    val_acc, val_loss = validate_epoch(\n","        model,\n","        Wiki_val_loader if dataset == \"Wiki\" else PMQA_val_loader,\n","        loss_fn,\n","        device,\n","        len(Wiki_val_dataset) if dataset == \"Wiki\" else len(PMQA_val_dataset),\n","        stat_fn\n","    )\n","    print(f'Validation loss {val_loss}, accuracy {val_acc}')\n"]},{"cell_type":"markdown","metadata":{"id":"5zI_cgLkNBca"},"source":["### Model Evaluation"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32176,"status":"ok","timestamp":1702904574727,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"sbrrn-EU2U4w","outputId":"d221e335-fe90-4b71-b977-a3c7c534f04b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Testing: 100%|██████████| 107/107 [00:31<00:00,  3.36it/s]"]},{"name":"stdout","output_type":"stream","text":["Test loss 0.0019573090134501875, accuracy 0.9994117647058822\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["test_acc, test_loss = eval_model(\n","    model,\n","    Wiki_test_loader if dataset == \"Wiki\" else PMQA_test_loader,\n","    loss_fn,\n","    device,\n","    len(Wiki_test_dataset) if dataset == \"Wiki\" else len(PMQA_test_dataset),\n","    stat_fn\n",")\n","\n","print(f'Test loss {test_loss}, accuracy {test_acc}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702886098070,"user":{"displayName":"Andrew Yi","userId":"18430212292193098798"},"user_tz":300},"id":"FEsyb7v0bif5","outputId":"f96c3d65-7fc1-4f09-9970-9ba71b752735"},"outputs":[],"source":["\"\"\"\n","def preprocess(texts):\n","    # Tokenize the texts - this can be a single string or a list of strings\n","    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n","    return inputs\n","\n","def predict(model, texts, device):\n","    model.eval()  # Set the model to evaluation mode\n","\n","    # Preprocess and tokenize the texts\n","    inputs = preprocess(texts)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention_mask = inputs['attention_mask'].to(device)\n","\n","    # Get predictions\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        predictions = torch.argmax(outputs, dim=1)\n","\n","    return predictions.cpu().numpy()  # Return predictions as numpy array\n","\n","text = \"As ILC2s are elevated in patients with CRSwNP, they may drive nasal polyp formation in CRS. ILC2s are also linked with high tissue and blood eosinophilia and have a potential role in the activation and survival of eosinophils during the Th2 immune response. The association of innate lymphoid cells in CRS provides insights into its pathogenesis.\"\n","single_prediction = predict(model, text, device)\n","print(single_prediction[0])\n","\"\"\""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["8h2vfTkIPyiM","TFtHvthyE34H"],"gpuType":"V100","machine_shape":"hm","provenance":[{"file_id":"1d7NJEtDOAdqRG6vk6_xwRiUKnxWhqb_9","timestamp":1702877726128},{"file_id":"1lnpLFe5_Zo5FfpT1X8EBsgFZUBBj2McQ","timestamp":1702853299455},{"file_id":"1iKMmKVhWcG-d3YziXvHd94r6ZQ3KyzDc","timestamp":1702798248712}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
