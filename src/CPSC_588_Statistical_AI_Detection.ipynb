{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du0JyQJvj-2k"
      },
      "source": [
        "### Setup: Install and import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InR32FS70N5v"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t46zhfzczpR"
      },
      "outputs": [],
      "source": [
        "# In order to make things work on google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cg1GBJFJEgGf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, AdamW\n",
        "import nltk\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwlAZPgW7Mxz"
      },
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY # PUT UR API KEY HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPSN1KjlrENp"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "\n",
        "# A small example\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80Icgps6EiDz"
      },
      "source": [
        "### Load Pre-trained RoBERTa Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_rU-1hnEl6L"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_base = RobertaModel.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h2vfTkIPyiM"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHbKUtamRDnF"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTd8SQe7P7wk"
      },
      "outputs": [],
      "source": [
        "# GPT- wiki-intro\n",
        "# https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"aadityaubhat/GPT-wiki-intro\")['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp0ylch3b3vY"
      },
      "outputs": [],
      "source": [
        "# truncate\n",
        "def truncate(example):\n",
        "    \"\"\"\n",
        "    Truncate 'wiki_intro' and 'generated_intro' to shorter length\n",
        "    \"\"\"\n",
        "    min_length = min(len(example['wiki_intro']), len(example['generated_intro']))\n",
        "    truncated_wiki_intro = example['wiki_intro'][:min_length]\n",
        "    truncated_generated_intro = example['generated_intro'][:min_length]\n",
        "\n",
        "    return {\n",
        "        'wiki_intro': truncated_wiki_intro,\n",
        "        'generated_intro': truncated_generated_intro,\n",
        "        'title_len': example['title_len'],\n",
        "        'wiki_intro_len': example['wiki_intro_len'],\n",
        "        'generated_intro_len': example['generated_intro_len'],\n",
        "        'prompt_tokens': example['prompt_tokens'],\n",
        "        'generated_text_tokens': example['generated_text_tokens']\n",
        "    }\n",
        "\n",
        "\n",
        "# Wiki_train_data = Wiki_train_data.map(truncate)\n",
        "# Wiki_val_data = Wiki_val_data.map(truncate)\n",
        "# Wiki_test_data = Wiki_test_data.map(truncate)\n",
        "Wiki_data = dataset.map(truncate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate labels\n",
        "Wiki_texts = Wiki_data['wiki_intro'] + Wiki_data['generated_intro']\n",
        "\n",
        "# 1 for human generated, 0 for machine generated\n",
        "Wiki_labels = [1] * len(Wiki_data['wiki_intro']) + [0] * len(Wiki_data['generated_intro'])"
      ],
      "metadata": {
        "id": "nxrp_vqf08GN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample_data(texts, labels, num_samples=2000):\n",
        "    combined_data = list(zip(texts, labels))\n",
        "    sampled_data = random.sample(combined_data, num_samples)\n",
        "    sampled_texts, sampled_labels = zip(*sampled_data)\n",
        "    sampled_indices = [texts.index(text) for text, label in sampled_data]\n",
        "\n",
        "    return list(sampled_texts), list(sampled_labels), sampled_indices\n"
      ],
      "metadata": {
        "id": "tmkK8t5Q1Hhd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Wiki_sampled_texts, Wiki_sampled_labels, Wiki_sampled_indices = downsample_data(Wiki_texts, Wiki_labels)\n",
        "\n",
        "Wiki_train_texts = Wiki_sampled_texts[:1700]\n",
        "Wiki_train_labels = Wiki_sampled_labels[:1700]\n",
        "Wiki_train_indices = Wiki_sampled_indices[:1700]\n",
        "\n",
        "Wiki_val_texts = Wiki_sampled_texts[1700:1850]\n",
        "Wiki_val_labels = Wiki_sampled_labels[1700:1850]\n",
        "Wiki_val_indices = Wiki_sampled_indices[1700:1850]\n",
        "\n",
        "Wiki_test_texts = Wiki_sampled_texts[1850:]\n",
        "Wiki_test_labels = Wiki_sampled_labels[1850:]\n",
        "Wiki_test_indices = Wiki_sampled_indices[1850:]"
      ],
      "metadata": {
        "id": "3kChBsi30-3i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Data Size: {len(Wiki_train_texts)}\")\n",
        "print(f\"Validation Data Size: {len(Wiki_val_texts)}\")\n",
        "print(f\"Testing Data Size: {len(Wiki_test_texts)}\")"
      ],
      "metadata": {
        "id": "j110YSU41Bkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the splits are mostly balanced\n",
        "print(sum(Wiki_train_labels))\n",
        "print(sum(Wiki_val_labels))\n",
        "print(sum(Wiki_test_labels))"
      ],
      "metadata": {
        "id": "eiQVVrvGAKxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vogXQSEIgfzb"
      },
      "outputs": [],
      "source": [
        "# PubMedQA\n",
        "# https://pubmedqa.github.io/\n",
        "\n",
        "# a directory structure in Files:\n",
        "# data/ori_pqaa.json      - 2.6 MB Downloaded from https://drive.google.com/file/d/15v1x6aQDlZymaHGP7cZJZZYFfeJt2NdS/view\n",
        "# data/ori_pqal.json      - 533.4 MB Downloaded from https://github.com/pubmedqa/pubmedqa/blob/master/data/ori_pqal.json\n",
        "import json\n",
        "import random\n",
        "\n",
        "ori_pqal_path = './gdrive/MyDrive/CPSC_588_dataset/ori_pqal.json'\n",
        "with open(ori_pqal_path, 'r') as file:\n",
        "    ori_pqal = json.load(file)\n",
        "machine_generated_dataset = [{\"text\": item[\"LONG_ANSWER\"], \"label\": \"0\"} for item in ori_pqal.values()]\n",
        "\n",
        "ori_pqaa_path = './gdrive/MyDrive/CPSC_588_dataset/ori_pqaa.json'\n",
        "with open(ori_pqaa_path, 'r') as file:\n",
        "    ori_pqaa = json.load(file)\n",
        "human_generated_dataset = [{\"text\": item[\"LONG_ANSWER\"], \"label\": \"1\"} for item in ori_pqaa.values()]\n",
        "\n",
        "human_generated_dataset = random.sample(human_generated_dataset, 1000)\n",
        "\n",
        "print(machine_generated_dataset[0]) # {'text': '...', 'label': 'machine_generated'}\n",
        "print(human_generated_dataset[0]) # {'text': '...', 'label': 'human_generated'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cy5EPcMRragj"
      },
      "outputs": [],
      "source": [
        "combined_dataset = machine_generated_dataset + human_generated_dataset\n",
        "\n",
        "texts = [item['text'] for item in combined_dataset]\n",
        "labels = [int(item['label']) for item in combined_dataset]\n",
        "\n",
        "PMQA_train_texts, temp_texts, PMQA_train_labels, temp_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "PMQA_val_texts, PMQA_test_texts, PMQA_val_labels, PMQA_test_labels = train_test_split(\n",
        "    temp_texts, temp_labels, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PMQA_sampled_texts, PMQA_sampled_labels, PMQA_sampled_indices = downsample_data(texts, labels, 2000)\n",
        "\n",
        "PMQA_train_texts = PMQA_sampled_texts[:1700]\n",
        "PMQA_train_labels = PMQA_sampled_labels[:1700]\n",
        "PMQA_train_indices = PMQA_sampled_indices[:1700]\n",
        "\n",
        "PMQA_val_texts = PMQA_sampled_texts[1700:1850]\n",
        "PMQA_val_labels = PMQA_sampled_labels[1700:1850]\n",
        "PMQA_val_indices = PMQA_sampled_indices[1700:1850]\n",
        "\n",
        "PMQA_test_texts = PMQA_sampled_texts[1850:]\n",
        "PMQA_test_labels = PMQA_sampled_labels[1850:]\n",
        "PMQA_test_indices = PMQA_sampled_indices[1850:]"
      ],
      "metadata": {
        "id": "TFL_X8_Srowi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Data Size: {len(PMQA_train_texts)}\")\n",
        "print(f\"Validation Data Size: {len(PMQA_val_texts)}\")\n",
        "print(f\"Testing Data Size: {len(PMQA_test_texts)}\")"
      ],
      "metadata": {
        "id": "YgDBxpbVsEyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load testing dataset from json\n",
        "load_path = './gdrive/MyDrive/CPSC_588_dataset/ghostbuster/ghostbuster_data.json'\n",
        "\n",
        "with open(load_path, 'r', encoding='utf-8') as json_file:\n",
        "    loaded_data = json.load(json_file)\n",
        "\n",
        "gb_texts = loaded_data['texts']\n",
        "gb_labels = loaded_data['labels']\n",
        "\n",
        "\n",
        "gb_sampled_texts, gb_sampled_labels, gb_sampled_indices = downsample_data(gb_texts, gb_labels, 200)\n",
        "print(sum(gb_sampled_labels))"
      ],
      "metadata": {
        "id": "RKGUMnxZdb8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFtHvthyE34H"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PH19Mj7IM4hW"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.texts[item])\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          return_token_type_ids=False,\n",
        "          padding='max_length',\n",
        "          return_attention_mask=True,\n",
        "          return_tensors='pt',\n",
        "          truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "          'text': text,\n",
        "          'input_ids': encoding['input_ids'].flatten(),\n",
        "          'attention_mask': encoding['attention_mask'].flatten(),\n",
        "          'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "Wiki_train_dataset = TextDataset(Wiki_train_texts, Wiki_train_labels, tokenizer)\n",
        "Wiki_val_dataset = TextDataset(Wiki_val_texts, Wiki_val_labels, tokenizer)\n",
        "Wiki_test_dataset = TextDataset(Wiki_test_texts, Wiki_test_labels, tokenizer)\n",
        "\n",
        "Wiki_train_loader = DataLoader(Wiki_train_dataset, batch_size=16, shuffle=True)\n",
        "Wiki_val_loader = DataLoader(Wiki_val_dataset, batch_size=16, shuffle=True)\n",
        "Wiki_test_loader = DataLoader(Wiki_test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "PMQA_train_dataset = TextDataset(PMQA_train_texts, PMQA_train_labels, tokenizer)\n",
        "PMQA_val_dataset = TextDataset(PMQA_val_texts, PMQA_val_labels, tokenizer)\n",
        "PMQA_test_dataset = TextDataset(PMQA_test_texts, PMQA_test_labels, tokenizer)\n",
        "\n",
        "PMQA_train_loader = DataLoader(PMQA_train_dataset, batch_size=16, shuffle=True)\n",
        "PMQA_val_loader = DataLoader(PMQA_val_dataset, batch_size=16, shuffle=False)\n",
        "PMQA_test_loader = DataLoader(PMQA_test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPf-nItAMxG6"
      },
      "source": [
        "### Create a Custom Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "h2yuRC4hE0Yb"
      },
      "outputs": [],
      "source": [
        "class RobertaClassifier(nn.Module):\n",
        "    def __init__(self, roberta_base, stat_emb_dim, fusion_type='early'):\n",
        "        super(RobertaClassifier, self).__init__()\n",
        "        self.fusion_type = fusion_type\n",
        "        self.roberta = roberta_base\n",
        "\n",
        "        # Non-linear transformation for statistical embeddings\n",
        "        self.stat_emb_transform = nn.Linear(stat_emb_dim, stat_emb_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        if fusion_type == 'early':\n",
        "            self.classifier = nn.Linear(roberta_base.config.hidden_size + stat_emb_dim, 2)\n",
        "        else:  # late fusion\n",
        "            self.classifier = nn.Linear(roberta_base.config.hidden_size, 2)\n",
        "            self.stat_emb_classifier = nn.Linear(stat_emb_dim, 2)\n",
        "\n",
        "            # Conditional layer\n",
        "            self.conditional_weights = nn.Linear(stat_emb_dim, roberta_base.config.hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, statistical_features):\n",
        "        outputs = self.roberta(input_ids, attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        # Apply non-linear transformation to statistical features\n",
        "        transformed_stat_features = self.activation(self.stat_emb_transform(statistical_features))\n",
        "\n",
        "        if self.fusion_type == 'early':\n",
        "            combined_output = torch.cat((pooled_output, transformed_stat_features), dim=1)\n",
        "            return self.classifier(combined_output)\n",
        "        else:  # late fusion\n",
        "            # Apply conditional layer\n",
        "            conditional_weights = torch.sigmoid(self.conditional_weights(transformed_stat_features))\n",
        "            conditioned_roberta_output = pooled_output * conditional_weights\n",
        "\n",
        "            logits_from_roberta = self.classifier(conditioned_roberta_output)\n",
        "            logits_from_stat_emb = self.stat_emb_classifier(transformed_stat_features)\n",
        "            combined_logits = logits_from_roberta + logits_from_stat_emb\n",
        "            return combined_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_KVxhJWodqO"
      },
      "source": [
        "### Create a Custom Attacker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GdijFfzHodBM"
      },
      "outputs": [],
      "source": [
        "class LLMAttacker():\n",
        "    def __init__(self, model=\"gpt-3.5-turbo\", paraphrase_prompt=None, in_context_prompt=None):\n",
        "        self.model = model\n",
        "        self.paraphrase_prompt = paraphrase_prompt\n",
        "        self.in_context_prompt = in_context_prompt\n",
        "\n",
        "    def generate_in_context_prompt(self, features):\n",
        "        return None\n",
        "\n",
        "    def attack(self, mode, text, features=None):\n",
        "        message = \"\"\n",
        "\n",
        "        # Human written and predicted human written\n",
        "        if mode == \"paraphrase\":\n",
        "            completion= client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": self.paraphrase_prompt},\n",
        "                    {\"role\": \"user\", f\"content\": \"Text: {text}\"}\n",
        "                ],\n",
        "                max_tokens=128\n",
        "            )\n",
        "            message = completion.choices[0].message.content.strip()\n",
        "\n",
        "        # AI-generated and predicted AI-generated\n",
        "        elif mode == \"in_context\":\n",
        "            completion = client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": self.in_context_prompt},\n",
        "                    {\"role\": \"user\", f\"content\": \"Text: {text}\"}\n",
        "                ],\n",
        "                max_tokens=128\n",
        "            )\n",
        "            message = completion.choices[0].message.content.strip()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid attack mode\")\n",
        "\n",
        "        return message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-3GpWbBEWiiv"
      },
      "outputs": [],
      "source": [
        "# # word embedding\n",
        "# from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# output_file = './gdrive/MyDrive/CPSC_588_dataset/word_embeddings_wiki.pt'\n",
        "\n",
        "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "# model = RobertaModel.from_pretrained('roberta-base').to(device)\n",
        "\n",
        "# pbar = tqdm(total=len(Wiki_train_texts), desc=\"Processing texts\")\n",
        "\n",
        "# embeddings_list = []\n",
        "\n",
        "# for text in Wiki_train_texts:\n",
        "#     inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "#     outputs = model(**inputs)\n",
        "#     embeddings = outputs.last_hidden_state.mean(dim=1).detach().cpu()\n",
        "#     embeddings_list.append(embeddings)\n",
        "#     pbar.update(1)\n",
        "\n",
        "# pbar.close()\n",
        "\n",
        "# embeddings = torch.cat(embeddings_list, dim=0)\n",
        "\n",
        "# torch.save(embeddings, output_file)\n",
        "\n",
        "# print(f\"Embeddings saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTJ-wQSNWouG"
      },
      "outputs": [],
      "source": [
        "word_embeddings_loaded = torch.load(\"./gdrive/MyDrive/CPSC_588_dataset/word_embeddings_wiki.pt\")\n",
        "print(word_embeddings_loaded[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # word embedding of PMQA\n",
        "# from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# output_file = './gdrive/MyDrive/CPSC_588_dataset/word_embeddings_pmqa.pt'\n",
        "\n",
        "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "# model = RobertaModel.from_pretrained('roberta-base').to(device)\n",
        "\n",
        "# pbar = tqdm(total=len(PMQA_train_texts), desc=\"Processing texts\")\n",
        "\n",
        "# embeddings_list = []\n",
        "\n",
        "# for text in PMQA_train_texts:\n",
        "#     inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "#     outputs = model(**inputs)\n",
        "#     embeddings = outputs.last_hidden_state.mean(dim=1).detach().cpu()\n",
        "#     embeddings_list.append(embeddings)\n",
        "#     pbar.update(1)\n",
        "\n",
        "# pbar.close()\n",
        "\n",
        "# embeddings = torch.cat(embeddings_list, dim=0)\n",
        "\n",
        "# torch.save(embeddings, output_file)\n",
        "\n",
        "# print(f\"Embeddings saved to {output_file}\")"
      ],
      "metadata": {
        "id": "MXttint0zY9E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings_loaded = torch.load(\"./gdrive/MyDrive/CPSC_588_dataset/word_embeddings_pmqa.pt\")\n",
        "print(word_embeddings_loaded[:5])\n",
        "print(len(word_embeddings_loaded))"
      ],
      "metadata": {
        "id": "si9TxJiQzbV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X_fN8Ha_FRS"
      },
      "source": [
        "### Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Paper here: https://arxiv.org/pdf/2306.04723.pdf\n",
        "\n",
        "Code here: https://github.com/ArGintum/GPTID/blob/main/IntrinsicDim.py\n",
        "\n",
        "Maybe a good feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0NlwqNnntOuL"
      },
      "outputs": [],
      "source": [
        "# https://github.com/ArGintum/GPTID/blob/main/IntrinsicDim.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "from threading import Thread\n",
        "\n",
        "MINIMAL_CLOUD = 47\n",
        "\n",
        "def prim_tree(adj_matrix, alpha=1.0):\n",
        "    infty = np.max(adj_matrix) + 10\n",
        "\n",
        "    dst = np.ones(adj_matrix.shape[0]) * infty\n",
        "    visited = np.zeros(adj_matrix.shape[0], dtype=bool)\n",
        "    ancestor = -np.ones(adj_matrix.shape[0], dtype=int)\n",
        "\n",
        "    v, s = 0, 0.0\n",
        "    for i in range(adj_matrix.shape[0] - 1):\n",
        "        visited[v] = 1\n",
        "        ancestor[dst > adj_matrix[v]] = v\n",
        "        dst = np.minimum(dst, adj_matrix[v])\n",
        "        dst[visited] = infty\n",
        "\n",
        "        v = np.argmin(dst)\n",
        "        s += (adj_matrix[v][ancestor[v]] ** alpha)\n",
        "\n",
        "    return s.item()\n",
        "\n",
        "def process_string(sss):\n",
        "    return sss.replace('\\n', ' ').replace('  ', ' ')\n",
        "\n",
        "class PHD():\n",
        "    def __init__(self, alpha=1.0, metric='euclidean', n_reruns=3, n_points=7, n_points_min=3):\n",
        "        '''\n",
        "        Initializes the instance of PH-dim computer\n",
        "        Parameters:\n",
        "            1) alpha --- real-valued parameter Alpha for computing PH-dim (see the reference paper). Alpha should be chosen lower than\n",
        "        the ground-truth Intrinsic Dimensionality; however, Alpha=1.0 works just fine for our kind of data.\n",
        "            2) metric --- String or Callable, distance function for the metric space (see documentation for Scipy.cdist)\n",
        "            3) n_reruns --- Number of restarts of whole calculations (each restart is made in a separate thread)\n",
        "            4) n_points --- Number of subsamples to be drawn at each subsample\n",
        "            5) n_points_min --- Number of subsamples to be drawn at larger subsamples (more than half of the point cloud)\n",
        "        '''\n",
        "        self.alpha = alpha\n",
        "        self.n_reruns = n_reruns\n",
        "        self.n_points = n_points\n",
        "        self.n_points_min = n_points_min\n",
        "        self.metric = metric\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def _sample_W(self, W, nSamples):\n",
        "        n = W.shape[0]\n",
        "        random_indices = np.random.choice(n, size=nSamples, replace=False)\n",
        "        return W[random_indices]\n",
        "\n",
        "    def _calc_ph_dim_single(self, W, test_n, outp, thread_id):\n",
        "        lengths = []\n",
        "        for n in test_n:\n",
        "            if W.shape[0] <= 2 * n:\n",
        "                restarts = self.n_points_min\n",
        "            else:\n",
        "                restarts = self.n_points\n",
        "\n",
        "            reruns = np.ones(restarts)\n",
        "            for i in range(restarts):\n",
        "                tmp = self._sample_W(W, n)\n",
        "                reruns[i] = prim_tree(cdist(tmp, tmp, metric=self.metric), self.alpha)\n",
        "\n",
        "            lengths.append(np.median(reruns))\n",
        "        lengths = np.array(lengths)\n",
        "\n",
        "        x = np.log(np.array(list(test_n)))\n",
        "        y = np.log(lengths)\n",
        "        N = len(x)\n",
        "        outp[thread_id] = (N * (x * y).sum() - x.sum() * y.sum()) / (N * (x ** 2).sum() - x.sum() ** 2)\n",
        "\n",
        "    def fit_transform(self, X, y=None, min_points=50, max_points=512, point_jump=40):\n",
        "        '''\n",
        "        Computing the PH-dim\n",
        "        Parameters:\n",
        "            1) X --- point cloud of shape (n_points, n_features),\n",
        "            2) y --- fictional parameter to fit with Sklearn interface\n",
        "            3) min_points --- size of minimal subsample to be drawn\n",
        "            4) max_points --- size of maximal subsample to be drawn\n",
        "            5) point_jump --- step between subsamples\n",
        "        '''\n",
        "        ms = np.zeros(self.n_reruns)\n",
        "        test_n = range(min_points, max_points, point_jump)\n",
        "        threads = []\n",
        "\n",
        "        for i in range(self.n_reruns):\n",
        "            threads.append(Thread(target=self._calc_ph_dim_single, args=[X, test_n, ms, i]))\n",
        "            threads[-1].start()\n",
        "\n",
        "        for i in range(self.n_reruns):\n",
        "            threads[i].join()\n",
        "\n",
        "        m = np.mean(ms)\n",
        "        return 1 / (1 - m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07FwZCgfuXZL"
      },
      "source": [
        "### Calculate the statistical features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "nltk.help.upenn_tagset()\n"
      ],
      "metadata": {
        "id": "wJ_7ohsMD-dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.data import load\n",
        "upenn_tagset_info = load('help/tagsets/upenn_tagset.pickle')\n",
        "upenn_tagset = list(upenn_tagset_info.keys())\n",
        "#print(upenn_tagset)\n",
        "#print(len(upenn_tagset))\n",
        "for index, tag in enumerate(upenn_tagset):\n",
        "    print(f\"index:{index} , tag:{tag}\")\n",
        "upenn_tagset_meaningful = upenn_tagset[0:3] + upenn_tagset[4:9] + upenn_tagset[10:14] + upenn_tagset[15:19] + upenn_tagset[25:]\n",
        "#print(upenn_tagset_meaningful)\n",
        "#print(len(upenn_tagset_meaningful))"
      ],
      "metadata": {
        "id": "N7gQV4SaENXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n"
      ],
      "metadata": {
        "id": "hby-GPxcEPBk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tag_dist(text: str):\n",
        "    text = nltk.tokenize.word_tokenize(text)\n",
        "    tagged_text = nltk.pos_tag(text)\n",
        "    tag_fd = nltk.FreqDist(tag for (word, tag) in tagged_text)\n",
        "    tag_count = [tag_fd.get(tag, 0) for tag in upenn_tagset_meaningful]\n",
        "    count_sum = sum(tag_count)\n",
        "    tag_dist = [count / count_sum for count in tag_count]\n",
        "    # tag_dist = [tag_fd.freq(tag) for tag in tag_fd]\n",
        "    # print(dict(tag_fd))\n",
        "    # print(\"length\", len(tag_dist))\n",
        "    # print(tag_dist)\n",
        "    return tag_dist\n",
        "\n",
        "def calculate_statistical_features_pos(input_text):\n",
        "    # Implement the logic to calculate statistical features\n",
        "    # This function should return a tensor of shape [batch_size, stat_emb_dim]\n",
        "    # pos tag distribution\n",
        "    pos_tag_dists = [calculate_tag_dist(text) for text in input_text]\n",
        "    return torch.tensor(pos_tag_dists)\n",
        "\n",
        "# pos_embeddings = calculate_statistical_features_pos(Wiki_train_texts)\n",
        "# torch.save(pos_embeddings, \"/content/gdrive/MyDrive/CPSC_588_dataset/pos_embeddings_wiki.pt\")\n"
      ],
      "metadata": {
        "id": "aYifnUVbEVBC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pos_embeddings = calculate_statistical_features_pos(PMQA_train_texts)\n",
        "# torch.save(pos_embeddings, \"/content/gdrive/MyDrive/CPSC_588_dataset/pos_embeddings_pmqa.pt\")"
      ],
      "metadata": {
        "id": "0r34VpRGEbU2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pos_embeddings_wiki = torch.load(\"/content/gdrive/MyDrive/CPSC_588_dataset/pos_embeddings_wiki.pt\")\n",
        "# print(pos_embeddings_wiki[:2])\n",
        "# print(pos_embeddings_wiki.shape)\n",
        "# pos_embeddings_pmqa = torch.load(\"/content/gdrive/MyDrive/CPSC_588_dataset/pos_embeddings_pmqa.pt\")\n",
        "# print(pos_embeddings_pmqa[:2])\n",
        "# print(pos_embeddings_pmqa.shape)"
      ],
      "metadata": {
        "id": "hUjVMpTHEcdN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-readability-metrics"
      ],
      "metadata": {
        "id": "zDSsk8CNEd5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from readability import Readability"
      ],
      "metadata": {
        "id": "mlTESmWNEeXK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_readability_metrics(text):\n",
        "    metrics = []\n",
        "    r = Readability(text)\n",
        "    metrics.append(r.flesch_kincaid().score)\n",
        "    metrics.append(r.flesch().score)\n",
        "    metrics.append(r.gunning_fog().score)\n",
        "    metrics.append(r.coleman_liau().score)\n",
        "    metrics.append(r.dale_chall().score)\n",
        "    metrics.append(r.ari().score)\n",
        "    metrics.append(r.linsear_write().score)\n",
        "    # metrics.append(r.smog().score)\n",
        "    metrics.append(r.spache().score)\n",
        "    return metrics\n",
        "\n",
        "def calculate_statistical_features_readability(input_text):\n",
        "    # Implement the logic to calculate statistical features\n",
        "    # This function should return a tensor of shape [batch_size, stat_emb_dim]\n",
        "    # readability measure\n",
        "    readability_metrics = []\n",
        "    for text in input_text:\n",
        "        appended = False\n",
        "        text_pad = text\n",
        "        for i in range(100):\n",
        "            try:\n",
        "                readability_metrics.append(calculate_readability_metrics(text_pad))\n",
        "                appended = True\n",
        "            except:\n",
        "                text_pad += text\n",
        "                continue\n",
        "            break\n",
        "        if i == 99:\n",
        "            if not appended:\n",
        "                readability_metrics.append(([0] * 8))\n",
        "    return torch.tensor(readability_metrics)\n",
        "\n",
        "# readability_embeddings = calculate_statistical_features_readability(Wiki_train_texts)\n",
        "# torch.save(readability_embeddings, \"/content/gdrive/MyDrive/CPSC_588_dataset/readability_embeddings_wiki.pt\")"
      ],
      "metadata": {
        "id": "L8IOunE-Emnl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# readability_embeddings = calculate_statistical_features_readability(PMQA_train_texts)\n",
        "# torch.save(readability_embeddings, \"/content/gdrive/MyDrive/CPSC_588_dataset/readability_embeddings_pmqa.pt\")"
      ],
      "metadata": {
        "id": "BJlkOQg3EpM5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read_embeddings_wiki = torch.load(\"/content/gdrive/MyDrive/CPSC_588_dataset/readability_embeddings_wiki.pt\")\n",
        "# print(read_embeddings_wiki[:5])\n",
        "# print(read_embeddings_wiki.shape)\n",
        "# read_embeddings_pmqa = torch.load(\"/content/gdrive/MyDrive/CPSC_588_dataset/readability_embeddings_pmqa.pt\")\n",
        "# print(read_embeddings_pmqa[:5])\n",
        "# print(read_embeddings_pmqa.shape)"
      ],
      "metadata": {
        "id": "zMyt4OsREqWK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_statistical_features(input_text):\n",
        "    pos_embs = calculate_statistical_features_pos(input_text)\n",
        "    read_embs = calculate_statistical_features_readability(input_text)\n",
        "    return torch.cat((pos_embs, read_embs), dim=1)"
      ],
      "metadata": {
        "id": "k0ee7VPogr03"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAswQlD1M3Gv"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sYhc6dQU2Lvq"
      },
      "outputs": [],
      "source": [
        "def train_epoch_baseline(model, attacker, data_loader, loss_fn, optimizer, device, n_examples, calculate_stat_features):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in tqdm(data_loader, total=len(data_loader), desc=\"Training\"):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        labels = d[\"labels\"].to(device)\n",
        "        stat_features = calculate_stat_features(d[\"text\"]).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def train_epoch_adversarial_emphasize(model, attacker, data_loader, loss_fn, optimizer, device, n_examples, calculate_stat_features):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in tqdm(data_loader, total=len(data_loader), desc=\"Training\"):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        labels = d[\"labels\"].to(device)\n",
        "        texts = d[\"text\"]\n",
        "        stat_features = calculate_stat_features(texts).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Attack and retrain if the prediction is correct\n",
        "        for idx, (pred, label, text) in enumerate(zip(preds, labels, texts)):\n",
        "            if pred == label:\n",
        "                attack_mode = \"paraphrase\" if label.item() == 1 else \"in_context\"  # Assuming 1 is human, 0 is AI\n",
        "                modified_text = attacker.attack(attack_mode, text, stat_features)\n",
        "                modified_stat_features = calculate_stat_features([modified_text]).to(device)\n",
        "                modified_output = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=modified_stat_features)\n",
        "                modified_loss = loss_fn(modified_output, labels)\n",
        "\n",
        "                # Add modified loss to original loss\n",
        "                loss += modified_loss\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item() / (len(preds) + 1))\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def train_epoch(model, attacker, data_loader, loss_fn, optimizer, device, n_examples, calculate_stat_features):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in tqdm(data_loader, total=len(data_loader), desc=\"Training\"):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        labels = d[\"labels\"].to(device)\n",
        "        texts = d[\"text\"]\n",
        "        stat_features = calculate_stat_features(texts).to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        adv_labels_list = []\n",
        "        adv_outputs_list = []\n",
        "\n",
        "        for idx, (pred, label, text) in enumerate(zip(preds, labels, texts)):\n",
        "            if pred == label:\n",
        "                attack_mode = \"paraphrase\" if label.item() == 1 else \"in_context\"  # Assuming 1 is human, 0 is AI\n",
        "                modified_text = attacker.attack(attack_mode, text, stat_features[idx].unsqueeze(0))  # Process one stat_feature at a time\n",
        "                modified_input_id = input_ids[idx].unsqueeze(0)  # Single instance\n",
        "                modified_attention_mask = attention_mask[idx].unsqueeze(0)  # Single instance\n",
        "                modified_stat_features = calculate_stat_features([modified_text]).to(device)\n",
        "\n",
        "                modified_output = model(input_ids=modified_input_id,\n",
        "                                        attention_mask=modified_attention_mask,\n",
        "                                        statistical_features=modified_stat_features)\n",
        "\n",
        "                # Store adversarial examples\n",
        "                adv_outputs_list.append(modified_output)\n",
        "                adv_labels_list.append(label.unsqueeze(0))\n",
        "\n",
        "        if adv_outputs_list:\n",
        "            adv_outputs = torch.cat(adv_outputs_list, dim=0)\n",
        "            adv_labels = torch.cat(adv_labels_list, dim=0)\n",
        "            combined_outputs = torch.cat((outputs, adv_outputs), dim=0)\n",
        "            combined_labels = torch.cat((labels, adv_labels), dim=0)\n",
        "            combined_loss = loss_fn(combined_outputs, combined_labels)\n",
        "            losses.append(combined_loss.item())\n",
        "        else:\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "        total_loss = combined_loss if adv_outputs_list else loss\n",
        "        total_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def validate_epoch(model, data_loader, loss_fn, device, n_examples, calculate_stat_features):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            labels = d[\"labels\"].to(device)\n",
        "            texts = d[\"text\"]\n",
        "            stat_features = calculate_stat_features(texts).to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples, calculate_stat_features):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in tqdm(data_loader, total=len(data_loader), desc=\"Testing\"):\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            labels = d[\"labels\"].to(device)\n",
        "            stat_features = calculate_stat_features(d[\"text\"]).to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, statistical_features=stat_features)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_kHHHeI9FaP"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "dataset = \"PMQA\" # \"PMQA\"\n",
        "\n",
        "num_epochs = 5\n",
        "stat_emb_dim = 44\n",
        "fusion_type = \"late\"\n",
        "LLM_model = \"gpt-3.5-turbo\"\n",
        "paraphrase_prompt = \"I have a piece of machine-generated text that I need paraphrased to sound more human-like. \"\n",
        "#paraphrase_prompt = \"I have a piece of machine-generated text that I need paraphrased to sound more human-like. The text primarily is about \"\n",
        "#+ (\"Wikipedia introduction for various topics.\" if dataset = \"Wiki\" else \"answering research questions with yes/no/maybe.\")\n",
        "in_context_prompt = \"I have a piece of human-written text that I need regenerated to maintain a style as close as possible to the original. The goal is to replicate the unique characteristics of the original text, such as its tone, word choice, sentence structure, and overall flow. \"\n",
        "#paraphrase_prompt = \"I have a piece of human-written text that I need regenerated to maintain a style as close as possible to the original. The goal is to replicate the unique characteristics of the original text, such as its tone, word choice, sentence structure, and overall flow. Please pay special attention to the nuances in language and the specific manner in which ideas are expressed. The text should read as if it were written by the same author, preserving the essence and subtlety of the original writing. This task is for adversarial training purposes, where the aim is to challenge machine prediction capabilities in distinguishing between human and machine-generated texts. The text in question [include or describe the text here, or specify its main themes or style]. Keep the length and format consistent with the original, and ensure that the regenerated text mirrors the original as closely as possible in all aspects. \"\n",
        "\n",
        "model = RobertaClassifier(roberta_base, stat_emb_dim, fusion_type)\n",
        "attacker = LLMAttacker(LLM_model, paraphrase_prompt, in_context_prompt)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "stat_fn = calculate_statistical_features\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        attacker,\n",
        "        Wiki_train_loader if dataset == \"Wiki\" else PMQA_train_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        device,\n",
        "        len(Wiki_train_dataset) if dataset == \"Wiki\" else len(PMQA_train_dataset),\n",
        "        stat_fn\n",
        "    )\n",
        "    print(f'Train loss {train_loss}, accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = validate_epoch(\n",
        "        model,\n",
        "        Wiki_val_loader if dataset == \"Wiki\" else PMQA_val_loader,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        len(Wiki_val_dataset) if dataset == \"Wiki\" else len(PMQA_val_dataset),\n",
        "        stat_fn\n",
        "    )\n",
        "    print(f'Validation loss {val_loss}, accuracy {val_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zI_cgLkNBca"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbrrn-EU2U4w"
      },
      "outputs": [],
      "source": [
        "test_acc, test_loss = eval_model(\n",
        "    model,\n",
        "    Wiki_test_loader if dataset == \"Wiki\" else PMQA_test_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(Wiki_test_dataset) if dataset == \"Wiki\" else len(PMQA_test_dataset),\n",
        "    stat_fn\n",
        ")\n",
        "\n",
        "print(f'Test loss {test_loss}, accuracy {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Trained Model"
      ],
      "metadata": {
        "id": "WjB9RXFATPAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts):\n",
        "    # Tokenize the texts - this can be a single string or a list of strings\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    return inputs\n",
        "\n",
        "def predict(model, texts, device):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = preprocess(texts)\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    return predictions.cpu().numpy()"
      ],
      "metadata": {
        "id": "jU1X0rhWTOje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"As ILC2s are elevated in patients with CRSwNP, they may drive nasal polyp formation in CRS. ILC2s are also linked with high tissue and blood eosinophilia and have a potential role in the activation and survival of eosinophils during the Th2 immune response. The association of innate lymphoid cells in CRS provides insights into its pathogenesis.\"\n",
        "single_prediction = predict(model, text, device)\n",
        "print(single_prediction[0])"
      ],
      "metadata": {
        "id": "97RfOazrTTRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Du0JyQJvj-2k",
        "80Icgps6EiDz",
        "8h2vfTkIPyiM",
        "TFtHvthyE34H",
        "SPf-nItAMxG6",
        "4X_fN8Ha_FRS",
        "07FwZCgfuXZL"
      ],
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}